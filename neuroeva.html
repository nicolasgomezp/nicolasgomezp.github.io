<html>
<body>
    <div style="position: relative;">
        <video id="webcam" width="640" height="480" autoplay style="position: relative; z-index: 1;"></video>
        <div id="output" style="position: absolute; top: 10px; left: 10px; color: white; background-color: rgba(0, 0, 0, 0.5); padding: 5px; z-index: 2;"></div>
    </div>
    <canvas id="canvas" width="640" height="480" style="display:none;"></canvas>
    <button id="analyzeDetailedButton">Detailed Analysis</button>
    <button id="analyzeShortButton">Short Description</button>
    <button id="analyzeResolveButton">Lee</button>
    <button id="toggleContinuousButton">Start Continuous</button>
    <button id="switchCameraButton">Switch Camera</button>
    <button id="analyzeSingleButton" style="background-color: red; color: white;">Single Analysis</button>

    <script src="https://js.puter.com/v2/"></script>
    <script>
        const video = document.getElementById('webcam');
        const canvas = document.getElementById('canvas');
        const outputDiv = document.getElementById('output');
        const analyzeDetailedButton = document.getElementById('analyzeDetailedButton');
        const analyzeShortButton = document.getElementById('analyzeShortButton');
        const analyzeResolveButton = document.getElementById('analyzeResolveButton');
        const toggleContinuousButton = document.getElementById('toggleContinuousButton');
        const switchCameraButton = document.getElementById('switchCameraButton');
        const analyzeSingleButton = document.getElementById('analyzeSingleButton');  // Added
        const context = canvas.getContext('2d');

        let currentStream = null;
        let facingMode = 'environment';
        let isSpeaking = false;
        let continuousAnalysisInterval;
        let selectedAnalysisType = null; // Store selected button
        let typingSpeed = 20; // Velocidad de escritura (milisegundos por letra)

        async function startWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: facingMode }
                });
                handleStream(stream);
            } catch (err) {
                console.error("Error accessing webcam:", err);
                outputDiv.textContent = "Error accessing webcam. Please check permissions.";
            }
        }

        function handleStream(stream) {
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }
            video.srcObject = stream;
            currentStream = stream;
        }

        function captureImage() {
            context.drawImage(video, 0, 0, 640, 480);
            const imageDataURL = canvas.toDataURL('image/jpeg');
            return imageDataURL;
        }

        function speak(text) {
            return new Promise((resolve, reject) => { // Return a Promise
                if (isSpeaking) {
                    window.speechSynthesis.cancel();
                }

                const utterance = new SpeechSynthesisUtterance(text);

                // Here's where you can improve the voice:
                utterance.voice = window.speechSynthesis.getVoices().find(voice => voice.lang === 'es-ES' || voice.lang === 'es'); // Try Spanish voice
                if (!utterance.voice){
                    utterance.voice = window.speechSynthesis.getVoices().find(voice => voice.lang === 'en-US' || voice.lang === 'en');
                    if (!utterance.voice){
                        console.warn("No suitable voice found. Using default.");
                    }
                }
                utterance.pitch = 1;    // Default: 1 (0 to 2) - Can experiment with values around 0.8 to 1.2
                utterance.rate = 1;     // Default: 1 (0.1 to 10) - Can experiment with values around 0.9 to 1.1
                utterance.volume = 1;   // Default: 1 (0 to 1)

                utterance.onstart = () => {
                    isSpeaking = true;
                };

                utterance.onend = () => {
                    isSpeaking = false;
                    resolve(); // Resolve the Promise when speech ends
                };

                utterance.onerror = () => {
                    isSpeaking = false;
                    console.error("Speech synthesis error.");
                    reject("Speech synthesis error.");  // Reject the Promise if there's an error
                };

                window.speechSynthesis.speak(utterance);
            });
        }

        async function typeWriter(text, element) {
            element.textContent = ""; // Clear the outputDiv
            let i = 0;
            return new Promise((resolve) => {
                function next() {
                    if (i < text.length) {
                        element.textContent += text.charAt(i);
                        i++;
                        setTimeout(next, typingSpeed);
                    } else {
                        resolve();
                    }
                }
                next();
            });
        }

        async function analyzeImage(prompt) {
            if (isSpeaking) {
                return; //Don't start a new analysis if one is already in progress.
            }

            outputDiv.textContent = "Analizando...";
            try {
                const imageBase64 = captureImage();
                const response = await puter.ai.chat(
                    prompt,
                    imageBase64
                );

                await typeWriter(response, outputDiv); // Use the typewriter effect

                await speak(response); // Await the speech to finish
            } catch (error) {
                console.error("", error);
                await typeWriter("", outputDiv);
                await speak(""); // Await error speech to finish
            }
        }

        function startContinuousAnalysis() {
            if (selectedAnalysisType) {
                continuousAnalysisInterval = setInterval(async () => {  //Make it async
                    await analyzeImage(selectedAnalysisType.prompt); //Await the execution
                }, 2000);
            }
        }

        function stopContinuousAnalysis() {
            clearInterval(continuousAnalysisInterval);
        }

        function toggleContinuousAnalysis() {
            if (continuousAnalysisInterval) {
                stopContinuousAnalysis();
                toggleContinuousButton.textContent = "Start Continuous";
            } else {
                startContinuousAnalysis();
                toggleContinuousButton.textContent = "Stop Continuous";
            }
        }

        function selectAnalysisType(button, prompt) {
            // Reset background color for all buttons
            analyzeDetailedButton.style.backgroundColor = '';
            analyzeShortButton.style.backgroundColor = '';
            analyzeResolveButton.style.backgroundColor = '';
            analyzeSingleButton.style.backgroundColor = ''; // Reset color for the single analysis button.

            // Highlight selected button
            button.style.backgroundColor = 'lightgreen';

            selectedAnalysisType = { button: button, prompt: prompt }; //Store the button and it's prompt.
            stopContinuousAnalysis(); //If you click a new analysis mode, continuous analysis will be automatically stopped.
            toggleContinuousButton.textContent = "Start Continuous"

        }

        async function switchCamera() {
            facingMode = (facingMode === 'user') ? 'environment' : 'user';
            await startWebcam();
        }

        // Event listeners
        analyzeDetailedButton.addEventListener('click', () => selectAnalysisType(analyzeDetailedButton, "Describe la escena detalladamente."));
        analyzeShortButton.addEventListener('click', () => selectAnalysisType(analyzeShortButton, "Que ves? Maximo 3 palabras, puedes usar menos(1, 2), usa lenguaje natural."));
        analyzeResolveButton.addEventListener('click', () => selectAnalysisType(analyzeResolveButton, "Lee este texto, traduce al espanol si es necesario"));
        toggleContinuousButton.addEventListener('click', toggleContinuousAnalysis);
        switchCameraButton.addEventListener('click', switchCamera);
        analyzeSingleButton.addEventListener('click', async () => { // New event listener
            //Check to see that a prompt exists.
            if (selectedAnalysisType) {
                await analyzeImage(selectedAnalysisType.prompt);
            }else{
              outputDiv.textContent = "Por favor, selecciona un tipo de an√°lisis primero.";
            }
        });

        // Start the webcam when the page loads
        startWebcam();
    </script>
</body>
</html>
